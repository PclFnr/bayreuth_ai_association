<!DOCTYPE html><html lang="en" class="h-full antialiased __variable_01f60e __variable_a0637f"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/bayreuth_ai_association/_next/static/media/8935352d0bfcf3a9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/bayreuth_ai_association/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/bayreuth_ai_association/_next/static/chunks/webpack-ce4d567c9f2a94d3.js"/><script src="/bayreuth_ai_association/_next/static/chunks/fd9d1056-96f96ef28edce221.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/23-80ca076b01c7bb1f.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/main-app-28cdedace4fab0f2.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/231-829f56fdb7c75283.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/55-c141fc066ff4a19d.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/472-cd817ab664ce0632.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/app/layout-1cfcfb656b6cf4a5.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js" async=""></script><title>Backend families - Docs</title><meta name="description" content="Overview of backend families."/><link rel="icon" href="/bayreuth_ai_association/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/bayreuth_ai_association/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="flex min-h-full bg-white dark:bg-zinc-900"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="flex w-full flex-col"><header class="sticky top-0 z-50 flex flex-none flex-wrap items-center justify-between bg-white px-4 py-5 shadow-md shadow-zinc-900/5 transition duration-500 sm:px-6 lg:px-8 dark:shadow-none dark:bg-transparent"><div class="mr-6 flex lg:hidden"><button type="button" class="relative" aria-label="Open navigation"><svg aria-hidden="true" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke-linecap="round" class="h-6 w-6 stroke-zinc-500"><path d="M4 7h16M4 12h16M4 17h16"></path></svg></button><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div></div><div class="relative flex flex-grow basis-0 items-center"><a aria-label="Home page" href="/bayreuth_ai_association"><p>scikit-ollama</p></a></div><div class="-my-5 mr-6 sm:mr-8 md:mr-0"><button type="button" class="group flex h-6 w-6 items-center justify-center sm:justify-start md:h-auto md:w-80 md:flex-none md:rounded-lg md:py-2.5 md:pl-4 md:pr-3.5 md:text-sm md:ring-1 md:ring-zinc-200 md:hover:ring-zinc-300 lg:w-96 dark:md:bg-zinc-800/75 dark:md:ring-inset dark:md:ring-white/5 dark:md:hover:bg-zinc-700/40 dark:md:hover:ring-zinc-500"><svg aria-hidden="true" viewBox="0 0 20 20" class="h-5 w-5 flex-none fill-zinc-400 group-hover:fill-zinc-500 md:group-hover:fill-zinc-400 dark:fill-zinc-500"><path d="M16.293 17.707a1 1 0 0 0 1.414-1.414l-1.414 1.414ZM9 14a5 5 0 0 1-5-5H2a7 7 0 0 0 7 7v-2ZM4 9a5 5 0 0 1 5-5V2a7 7 0 0 0-7 7h2Zm5-5a5 5 0 0 1 5 5h2a7 7 0 0 0-7-7v2Zm8.707 12.293-3.757-3.757-1.414 1.414 3.757 3.757 1.414-1.414ZM14 9a4.98 4.98 0 0 1-1.464 3.536l1.414 1.414A6.98 6.98 0 0 0 16 9h-2Zm-1.464 3.536A4.98 4.98 0 0 1 9 14v2a6.98 6.98 0 0 0 4.95-2.05l-1.414-1.414Z"></path></svg><span class="sr-only md:not-sr-only md:ml-2 md:text-zinc-500 md:dark:text-zinc-400">Search docs</span></button><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div></div><div class="relative flex basis-0 justify-end gap-6 sm:gap-8 md:flex-grow"><div class="h-6 w-6"></div><a class="group" aria-label="GitHub" href="https://github.com/AndreasKarasenko/scikit-ollama"><svg aria-hidden="true" viewBox="0 0 16 16" class="h-6 w-6 fill-zinc-400 group-hover:fill-zinc-500 dark:group-hover:fill-zinc-300"><path d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z"></path></svg></a></div></header><div id="cde"></div><div class="relative mx-auto flex w-full max-w-8xl flex-auto justify-center sm:px-2 lg:px-8 xl:px-12"><div class="hidden lg:relative lg:block lg:flex-none"><div class="absolute inset-y-0 right-0 w-[50vw] bg-zinc-50 dark:hidden"></div><div class="absolute bottom-0 right-0 top-16 hidden h-12 w-px bg-gradient-to-t from-zinc-800 dark:block"></div><div class="absolute bottom-0 right-0 top-28 hidden w-px bg-zinc-800 dark:block"></div><div class="sticky top-[4.75rem] -ml-0.5 h-[calc(100vh-4.75rem)] w-64 overflow-y-auto overflow-x-hidden py-16 pl-0.5 pr-8 xl:w-72 xl:pr-16"><nav class="text-base lg:text-sm"><ul role="list" class="space-y-9"><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Introduction</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association">Home</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/about-our-meetings">About our meetings</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Text classification</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/zero-shot-text-classification">Zero-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/few-shot-text-classification">Few-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/dynamic-few-shot-text-classification">Dynamic few-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/tunable-text-classification">Tunable text classification</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Text-to-text modelling</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/text-summarization">Text summarization</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/text-translation">Text translation</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/tunable-text-to-text">Tunable text-to-text</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Resources</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/text-vectorization">Overview</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Contributing</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/how-to-contribute">How to contribute</a></li></ul></li></ul></nav></div></div><div class="min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16"><article><header class="mb-9 space-y-1"><h1 class="font-display text-3xl tracking-tight text-zinc-900 dark:text-white">Backend families</h1></header><div class="prose prose-teal max-w-none dark:prose-invert dark:text-teal-200 prose-headings:scroll-mt-28 prose-headings:font-display prose-headings:font-normal lg:prose-headings:scroll-mt-[8.5rem] prose-lead:text-teal-500 dark:prose-lead:text-teal-400 prose-a:font-semibold dark:prose-a:text-teal-400 prose-a:no-underline prose-a:shadow-[inset_0_-2px_0_0_var(--tw-prose-background,#fff),inset_0_calc(-1*(var(--tw-prose-underline-size,4px)+2px))_0_0_var(--tw-prose-underline,theme(colors.teal.300))] hover:prose-a:[--tw-prose-underline-size:6px] dark:[--tw-prose-background:theme(colors.teal.900)] dark:prose-a:shadow-[inset_0_calc(-1*var(--tw-prose-underline-size,2px))_0_0_var(--tw-prose-underline,theme(colors.teal.800))] dark:hover:prose-a:[--tw-prose-underline-size:6px] prose-pre:rounded-xl prose-pre:bg-zinc-900 prose-pre:shadow-lg dark:prose-pre:bg-zinc-700/40 dark:prose-pre:shadow-none dark:prose-pre:ring-1 dark:prose-pre:ring-zinc-100/10 dark:prose-hr:border-teal-800"><p>On a high level, Scikit-LLM estimators are divided based on the language model backend family they use. The backend family is defined by the API format and does not necessarily correspond to the language model architecture. For example, all backends that follow the OpenAI API format are groupped into <em>gpt</em> family regardless the actual language model architecture or provider. Eeach backend family has its own set of estimators which are located in the <code>skllm.models.&lt;family&gt;</code> sub-module.</p><p>For example, the Zero-Shot Classifier is available as <code>skllm.models.gpt.classification.zero_shot.ZeroShotGPTClassifier</code> for the <em>gpt</em> family, and as <code>skllm.models.vertex.classification.zero_shot.ZeroShotVertexClassifier</code> for the <em>vertex</em> family. The separation between the backend families is necessary to allow for a reasonable level of flexibility if/when model providers introduce model-specific features that are not supported by other providers and hence cannot be easily abstracted away. At the same time, the number of model families is kept to a minimum to simplify the usage and maintenance of the library. Since the OpenAI API is by far the most popular and widely used, backends that follow that format are preferred over the others.</p><p>Whenever the backend family supports multiple backends, the default one is used unless the <code>model</code> parameter specifies a particular backend namespace. For example, the default backend for the <em>gpt</em> family is the OpenAI backend. However, you can use the Azure backend by setting <code>model = &quot;azure::&lt;model_name&gt;&quot;</code>. However, please note that not every estimator supports every backend.</p><hr/><h2 id="gpt-family">GPT Family</h2><p>The GPT family includes all backends that follow the OpenAI API format.</p><h3 id="open-ai-default">OpenAI (default)</h3><p>The OpenAI backend is the default backend for the GPT family. It is used whenever the <code>model</code> parameter does not specify a particular backend namespace.</p><p>To use the OpenAI backend, you need to set your OpenAI API key and organization ID as follows:</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skllm</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">config </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> SKLLMConfig</span>
<!-- -->
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_openai_key</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;&lt;YOUR_KEY&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_openai_org</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;&lt;YOUR_ORGANIZATION_ID&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span>
</code></pre><h3 id="azure">Azure</h3><p>OpenAI models can be alternatively used as a part of the <a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service">Azure OpenAI service</a>. To use the Azure backend, you need to provide your Azure API key and endpoint as follows:</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skllm</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">config </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> SKLLMConfig</span>
<span class="token plain"></span><span class="token comment" style="color:#6a9955"># Found under: Resource Management (Left Sidebar) -&gt; Keys and Endpoint -&gt; KEY 1</span><span class="token plain"></span>
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_gpt_key</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;&lt;YOUR_KEY&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain"></span><span class="token comment" style="color:#6a9955"># Found under: Resource Management (Left Sidebar) -&gt; Keys and Endpoint -&gt; Endpoint</span><span class="token plain"></span>
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_azure_api_base</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;&lt;API_BASE&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a9955"># e.g. https://&lt;YOUR_PROJECT_NAME&gt;.openai.azure.com/</span>
</code></pre><p>When using the Azure backend, the model should be specified as <code>model = &quot;azure::&lt;model_deployment_name&gt;&quot;</code>. For example, if you created a <em>gpt-3.5</em> deployment under the name <em>my-model</em>, you should use <code>model = &quot;azure::my-model&quot;</code>.</p><h3 id="gpt-4-all">GPT4ALL</h3><p>GPT4ALL is an open-source library that provides a unified API for multiple small-scale language models, that can be run locally on a consumer-grade hardware, even without a GPU. To use the GPT4ALL backend, you need to install the corresponding extension as follows:</p><pre class="prism-code language-bash" style="color:#e4e4e7;font-style:normal"><code><span class="token plain">pip install scikit-llm[gpt4all]</span>
</code></pre><p>Then, you can use the GPT4ALL by specifying the model as <code>model = &quot;gpt4all::&lt;model_name&gt;&quot;</code>, which will be downloaded automatically. For the full list of available models, please refer to the <a href="https://gpt4all.io/index.html">GPT4ALL official documentation</a>.</p><div class="my-8 flex rounded-3xl p-6 bg-amber-50 dark:bg-zinc-800/60 dark:ring-1 dark:ring-zinc-300/10"><svg aria-hidden="true" viewBox="0 0 32 32" fill="none" class="h-8 w-8 flex-none [--icon-foreground:theme(colors.zinc.900)] [--icon-background:theme(colors.white)]"><defs><radialGradient cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" id=":S1:-gradient" gradientTransform="matrix(0 21 -21 0 20 11)"><stop stop-color="#F53803"></stop><stop stop-color="#FF7500" offset=".527"></stop><stop stop-color="#FDBA74" offset="1"></stop></radialGradient><radialGradient cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" id=":S1:-gradient-dark" gradientTransform="matrix(0 24.5001 -19.2498 0 16 5.5)"><stop stop-color="#F53803"></stop><stop stop-color="#FF7500" offset=".527"></stop><stop stop-color="#FDBA74" offset="1"></stop></radialGradient></defs><g class="dark:hidden"><circle cx="20" cy="20" r="12" fill="url(#:S1:-gradient)"></circle><path fill-rule="evenodd" clip-rule="evenodd" d="M20 24.995c0-1.855 1.094-3.501 2.427-4.792C24.61 18.087 26 15.07 26 12.231 26 7.133 21.523 3 16 3S6 7.133 6 12.23c0 2.84 1.389 5.857 3.573 7.973C10.906 21.494 12 23.14 12 24.995V27a2 2 0 0 0 2 2h4a2 2 0 0 0 2-2v-2.005Z" class="fill-[var(--icon-background)]" fill-opacity="0.5"></path><path d="M25 12.23c0 2.536-1.254 5.303-3.269 7.255l1.391 1.436c2.354-2.28 3.878-5.547 3.878-8.69h-2ZM16 4c5.047 0 9 3.759 9 8.23h2C27 6.508 21.998 2 16 2v2Zm-9 8.23C7 7.76 10.953 4 16 4V2C10.002 2 5 6.507 5 12.23h2Zm3.269 7.255C8.254 17.533 7 14.766 7 12.23H5c0 3.143 1.523 6.41 3.877 8.69l1.392-1.436ZM13 27v-2.005h-2V27h2Zm1 1a1 1 0 0 1-1-1h-2a3 3 0 0 0 3 3v-2Zm4 0h-4v2h4v-2Zm1-1a1 1 0 0 1-1 1v2a3 3 0 0 0 3-3h-2Zm0-2.005V27h2v-2.005h-2ZM8.877 20.921C10.132 22.136 11 23.538 11 24.995h2c0-2.253-1.32-4.143-2.731-5.51L8.877 20.92Zm12.854-1.436C20.32 20.852 19 22.742 19 24.995h2c0-1.457.869-2.859 2.122-4.074l-1.391-1.436Z" class="fill-[var(--icon-foreground)]"></path><path d="M20 26a1 1 0 1 0 0-2v2Zm-8-2a1 1 0 1 0 0 2v-2Zm2 0h-2v2h2v-2Zm1 1V13.5h-2V25h2Zm-5-11.5v1h2v-1h-2Zm3.5 4.5h5v-2h-5v2Zm8.5-3.5v-1h-2v1h2ZM20 24h-2v2h2v-2Zm-2 0h-4v2h4v-2Zm-1-10.5V25h2V13.5h-2Zm2.5-2.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2ZM18.5 18a3.5 3.5 0 0 0 3.5-3.5h-2a1.5 1.5 0 0 1-1.5 1.5v2ZM10 14.5a3.5 3.5 0 0 0 3.5 3.5v-2a1.5 1.5 0 0 1-1.5-1.5h-2Zm2.5-3.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2Z" class="fill-[var(--icon-foreground)]"></path></g><g class="hidden dark:inline"><path fill-rule="evenodd" clip-rule="evenodd" d="M16 2C10.002 2 5 6.507 5 12.23c0 3.144 1.523 6.411 3.877 8.691.75.727 1.363 1.52 1.734 2.353.185.415.574.726 1.028.726H12a1 1 0 0 0 1-1v-4.5a.5.5 0 0 0-.5-.5A3.5 3.5 0 0 1 9 14.5V14a3 3 0 1 1 6 0v9a1 1 0 1 0 2 0v-9a3 3 0 1 1 6 0v.5a3.5 3.5 0 0 1-3.5 3.5.5.5 0 0 0-.5.5V23a1 1 0 0 0 1 1h.36c.455 0 .844-.311 1.03-.726.37-.833.982-1.626 1.732-2.353 2.354-2.28 3.878-5.547 3.878-8.69C27 6.507 21.998 2 16 2Zm5 25a1 1 0 0 0-1-1h-8a1 1 0 0 0-1 1 3 3 0 0 0 3 3h4a3 3 0 0 0 3-3Zm-8-13v1.5a.5.5 0 0 1-.5.5 1.5 1.5 0 0 1-1.5-1.5V14a1 1 0 1 1 2 0Zm6.5 2a.5.5 0 0 1-.5-.5V14a1 1 0 1 1 2 0v.5a1.5 1.5 0 0 1-1.5 1.5Z" fill="url(#:S1:-gradient-dark)"></path></g></svg><div class="ml-4 flex-auto"><p class="m-0 font-display text-xl text-amber-900 dark:text-amber-500">Note</p><div class="prose mt-2.5 text-amber-800 [--tw-prose-underline:theme(colors.amber.400)] [--tw-prose-background:theme(colors.amber.50)] prose-a:text-amber-900 prose-code:text-amber-900 dark:text-zinc-300 dark:[--tw-prose-underline:theme(colors.amber.700)] dark:prose-code:text-zinc-300"><p>The models available through the GPT4ALL out of the box have very limited capabilities and are not recommended for most of the use cases. In addition, not all models are permitted for commercial use. Please check the license of the model you are using before deploying it in production.</p></div></div></div><h3 id="custom-url">Custom URL</h3><p>Custom URL backend allows to use any GPT estimator with any OpenAI-compatible provider (either running locally or in the cloud).</p><p>In order to use the backend, it is necessary to set a global custom url:</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skllm</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">config </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> SKLLMConfig</span>
<!-- -->
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_gpt_url</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;http://localhost:8000/&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<!-- -->
<span class="token plain">clf </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> ZeroShotGPTClassifier</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">model</span><span class="token operator" style="color:#a1a1aa">=</span><span class="token string" style="color:#fdba74">&quot;custom_url::&lt;custom_model_name&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span>
</code></pre><div class="my-8 flex rounded-3xl p-6 bg-amber-50 dark:bg-zinc-800/60 dark:ring-1 dark:ring-zinc-300/10"><svg aria-hidden="true" viewBox="0 0 32 32" fill="none" class="h-8 w-8 flex-none [--icon-foreground:theme(colors.zinc.900)] [--icon-background:theme(colors.white)]"><defs><radialGradient cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" id=":S2:-gradient" gradientTransform="matrix(0 21 -21 0 20 11)"><stop stop-color="#F53803"></stop><stop stop-color="#FF7500" offset=".527"></stop><stop stop-color="#FDBA74" offset="1"></stop></radialGradient><radialGradient cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" id=":S2:-gradient-dark" gradientTransform="matrix(0 24.5001 -19.2498 0 16 5.5)"><stop stop-color="#F53803"></stop><stop stop-color="#FF7500" offset=".527"></stop><stop stop-color="#FDBA74" offset="1"></stop></radialGradient></defs><g class="dark:hidden"><circle cx="20" cy="20" r="12" fill="url(#:S2:-gradient)"></circle><path fill-rule="evenodd" clip-rule="evenodd" d="M20 24.995c0-1.855 1.094-3.501 2.427-4.792C24.61 18.087 26 15.07 26 12.231 26 7.133 21.523 3 16 3S6 7.133 6 12.23c0 2.84 1.389 5.857 3.573 7.973C10.906 21.494 12 23.14 12 24.995V27a2 2 0 0 0 2 2h4a2 2 0 0 0 2-2v-2.005Z" class="fill-[var(--icon-background)]" fill-opacity="0.5"></path><path d="M25 12.23c0 2.536-1.254 5.303-3.269 7.255l1.391 1.436c2.354-2.28 3.878-5.547 3.878-8.69h-2ZM16 4c5.047 0 9 3.759 9 8.23h2C27 6.508 21.998 2 16 2v2Zm-9 8.23C7 7.76 10.953 4 16 4V2C10.002 2 5 6.507 5 12.23h2Zm3.269 7.255C8.254 17.533 7 14.766 7 12.23H5c0 3.143 1.523 6.41 3.877 8.69l1.392-1.436ZM13 27v-2.005h-2V27h2Zm1 1a1 1 0 0 1-1-1h-2a3 3 0 0 0 3 3v-2Zm4 0h-4v2h4v-2Zm1-1a1 1 0 0 1-1 1v2a3 3 0 0 0 3-3h-2Zm0-2.005V27h2v-2.005h-2ZM8.877 20.921C10.132 22.136 11 23.538 11 24.995h2c0-2.253-1.32-4.143-2.731-5.51L8.877 20.92Zm12.854-1.436C20.32 20.852 19 22.742 19 24.995h2c0-1.457.869-2.859 2.122-4.074l-1.391-1.436Z" class="fill-[var(--icon-foreground)]"></path><path d="M20 26a1 1 0 1 0 0-2v2Zm-8-2a1 1 0 1 0 0 2v-2Zm2 0h-2v2h2v-2Zm1 1V13.5h-2V25h2Zm-5-11.5v1h2v-1h-2Zm3.5 4.5h5v-2h-5v2Zm8.5-3.5v-1h-2v1h2ZM20 24h-2v2h2v-2Zm-2 0h-4v2h4v-2Zm-1-10.5V25h2V13.5h-2Zm2.5-2.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2ZM18.5 18a3.5 3.5 0 0 0 3.5-3.5h-2a1.5 1.5 0 0 1-1.5 1.5v2ZM10 14.5a3.5 3.5 0 0 0 3.5 3.5v-2a1.5 1.5 0 0 1-1.5-1.5h-2Zm2.5-3.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2Z" class="fill-[var(--icon-foreground)]"></path></g><g class="hidden dark:inline"><path fill-rule="evenodd" clip-rule="evenodd" d="M16 2C10.002 2 5 6.507 5 12.23c0 3.144 1.523 6.411 3.877 8.691.75.727 1.363 1.52 1.734 2.353.185.415.574.726 1.028.726H12a1 1 0 0 0 1-1v-4.5a.5.5 0 0 0-.5-.5A3.5 3.5 0 0 1 9 14.5V14a3 3 0 1 1 6 0v9a1 1 0 1 0 2 0v-9a3 3 0 1 1 6 0v.5a3.5 3.5 0 0 1-3.5 3.5.5.5 0 0 0-.5.5V23a1 1 0 0 0 1 1h.36c.455 0 .844-.311 1.03-.726.37-.833.982-1.626 1.732-2.353 2.354-2.28 3.878-5.547 3.878-8.69C27 6.507 21.998 2 16 2Zm5 25a1 1 0 0 0-1-1h-8a1 1 0 0 0-1 1 3 3 0 0 0 3 3h4a3 3 0 0 0 3-3Zm-8-13v1.5a.5.5 0 0 1-.5.5 1.5 1.5 0 0 1-1.5-1.5V14a1 1 0 1 1 2 0Zm6.5 2a.5.5 0 0 1-.5-.5V14a1 1 0 1 1 2 0v.5a1.5 1.5 0 0 1-1.5 1.5Z" fill="url(#:S2:-gradient-dark)"></path></g></svg><div class="ml-4 flex-auto"><p class="m-0 font-display text-xl text-amber-900 dark:text-amber-500">Note</p><div class="prose mt-2.5 text-amber-800 [--tw-prose-underline:theme(colors.amber.400)] [--tw-prose-background:theme(colors.amber.50)] prose-a:text-amber-900 prose-code:text-amber-900 dark:text-zinc-300 dark:[--tw-prose-underline:theme(colors.amber.700)] dark:prose-code:text-zinc-300"><p>When using <code>custom_url</code> and <code>openai</code> backends within the same script, it is necessary to reset the custom url configuration using <code>SKLLMConfig.reset_gpt_url()</code>.</p></div></div></div><hr/><h2 id="vertex-family">Vertex Family</h2><p>The Vertex family currently includes a single (default) backend, which is the Google Vertex AI.</p><p>In order to use the Vertex backend, you need to configure your Google Cloud credentials as follows:</p><ol><li><p>Log in to <a href="https://console.cloud.google.com/">Google Cloud Console</a> and <a href="https://developers.google.com/workspace/guides/create-project">create a Google Cloud project</a>. After the project is created, select this project from a list of projects next to the Google Cloud logo (upper left corner).</p></li><li><p>Search for <em>Vertex AI</em> in the search bar and select it from the list of services.</p></li><li><p>Install a Google Cloud CLI on the local machine by following <a href="https://cloud.google.com/sdk/docs/install">the steps from the official documentation</a>, and <a href="https://cloud.google.com/docs/authentication/application-default-credentials#personal">set the application default credentials</a> by running the following command:</p><pre class="prism-code language-bash" style="color:#e4e4e7;font-style:normal"><code><span class="token plain">gcloud auth application-default login</span>
</code></pre></li><li><p>Configure Scikit-LLM with your project ID:</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skllm</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">config </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> SKLLMConfig</span>
<!-- -->
<span class="token plain">SKLLMConfig</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">set_google_project</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;&lt;YOUR_PROJECT_ID&gt;&quot;</span><span class="token punctuation" style="color:#a1a1aa">)</span>
</code></pre></li></ol><p>Additionally, for tuning LLMs in Vertex, it is required to have to have 64 cores of the TPU v3 pod training resource. By default this quota is set to 0 cores and has to be increased as follows (ignore this if you are not planning to use the tunable estimators):</p><ol><li>Go to <a href="https://cloud.google.com/docs/quota/view-manage#requesting_higher_quota">Quotas</a> and filter them for “Restricted image training TPU V3 pod cores per region”.</li><li>Select “europe-west4” region (currently this is the only supported region).</li><li>Click on “Edit Quotas”, set the limit to 64 and submit the request.<!-- --> <!-- -->The request should be approved within a few hours, but it might take up to several days.</li></ol></div></article></div><div class="hidden xl:sticky xl:top-[4.75rem] xl:-mr-6 xl:block xl:h-[calc(100vh-4.75rem)] xl:flex-none xl:overflow-y-auto xl:py-16 xl:pr-6"><nav aria-labelledby="on-this-page-title" class="w-56"><h2 id="on-this-page-title" class="font-display text-sm font-medium text-zinc-900 dark:text-white">On this page</h2><ol role="list" class="mt-4 space-y-3 text-sm"><li><h3><a class="text-teal-500 dark:text-teal-200" href="#gpt-family">GPT Family</a></h3><ol role="list" class="mt-2 space-y-3 pl-5 text-zinc-500 dark:text-zinc-400"><li><a class="hover:text-zinc-600 dark:hover:text-zinc-300" href="#open-ai-default">OpenAI (default)</a></li><li><a class="hover:text-zinc-600 dark:hover:text-zinc-300" href="#azure">Azure</a></li><li><a class="hover:text-zinc-600 dark:hover:text-zinc-300" href="#gpt-4-all">GPT4ALL</a></li><li><a class="hover:text-zinc-600 dark:hover:text-zinc-300" href="#custom-url">Custom URL</a></li></ol></li><li><h3><a class="font-normal text-zinc-500 hover:text-zinc-600 dark:text-zinc-400 dark:hover:text-zinc-300" href="#vertex-family">Vertex Family</a></h3></li></ol></nav></div></div></div><script src="/bayreuth_ai_association/_next/static/chunks/webpack-ce4d567c9f2a94d3.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/bayreuth_ai_association/_next/static/media/8935352d0bfcf3a9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/bayreuth_ai_association/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n7:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[1747,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"472\",\"static/chunks/472-cd817ab664ce0632.js\",\"185\",\"static/chunks/app/layout-1cfcfb656b6cf4a5.js\"],\"Providers\"]\na:I[1227,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"472\",\"static/chunks/472-cd817ab664ce0632.js\",\"185\",\"static/chunks/app/layout-1cfcfb656b6cf4a5.js\"],\"Layout\"]\nb:I[231,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"52\",\"static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js\"],\"\"]\nd:I[6130,[],\"\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"KteObhGWKN4CvpFO1QXQU\",\"assetPrefix\":\"/bayreuth_ai_association\",\"initialCanonicalUrl\":\"/docs/introduction-backend-families\",\"initialTree\":[\"\",{\"children\":[\"docs\",{\"children\":[\"introduction-backend-families\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"docs\",{\"children\":[\"introduction-backend-families\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",\"$L6\"],null],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"docs\",\"children\",\"introduction-backend-families\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"docs\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"h-full antialiased __variable_01f60e __variable_a0637f\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"flex min-h-full bg-white dark:bg-zinc-900\",\"children\":[\"$\",\"$L9\",null,{\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex h-full flex-col items-center justify-center text-center\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-display text-sm font-medium text-zinc-900 dark:text-white\",\"children\":\"404\"}],[\"$\",\"h1\",null,{\"className\":\"mt-3 font-display text-3xl tracking-tight text-zinc-900 dark:text-white\",\"children\":\"Page not found\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm text-zinc-500 dark:text-zinc-400\",\"children\":\"Sorry, we couldn’t find the page you’re looking for.\"}],[\"$\",\"$Lb\",null,{\"href\":\"/\",\"className\":\"mt-8 text-sm font-medium text-zinc-900 dark:text-white\",\"children\":\"Go back home\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"f:I[4456,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"52\",\"static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js\"],\"DocsHeader\"]\n10:I[7408,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"52\",\"static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js\"],\"Fence\"]\n11:I[2553,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"52\",\"static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js\"],\"PrevNextLinks\"]\n12:I[817,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"52\",\"static/chunks/app/docs/introduction-backend-families/page-943682ebc1326b19.js\"],\"TableOfContents\"]\n"])</script><script>self.__next_f.push([1,"6:[[\"$\",\"div\",null,{\"className\":\"min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16\",\"children\":[[\"$\",\"article\",null,{\"children\":[[\"$\",\"$Lf\",null,{\"title\":\"Backend families\"}],[\"$\",\"div\",null,{\"className\":\"prose prose-teal max-w-none dark:prose-invert dark:text-teal-200 prose-headings:scroll-mt-28 prose-headings:font-display prose-headings:font-normal lg:prose-headings:scroll-mt-[8.5rem] prose-lead:text-teal-500 dark:prose-lead:text-teal-400 prose-a:font-semibold dark:prose-a:text-teal-400 prose-a:no-underline prose-a:shadow-[inset_0_-2px_0_0_var(--tw-prose-background,#fff),inset_0_calc(-1*(var(--tw-prose-underline-size,4px)+2px))_0_0_var(--tw-prose-underline,theme(colors.teal.300))] hover:prose-a:[--tw-prose-underline-size:6px] dark:[--tw-prose-background:theme(colors.teal.900)] dark:prose-a:shadow-[inset_0_calc(-1*var(--tw-prose-underline-size,2px))_0_0_var(--tw-prose-underline,theme(colors.teal.800))] dark:hover:prose-a:[--tw-prose-underline-size:6px] prose-pre:rounded-xl prose-pre:bg-zinc-900 prose-pre:shadow-lg dark:prose-pre:bg-zinc-700/40 dark:prose-pre:shadow-none dark:prose-pre:ring-1 dark:prose-pre:ring-zinc-100/10 dark:prose-hr:border-teal-800\",\"children\":[[\"$\",\"p\",null,{\"children\":[\"On a high level, Scikit-LLM estimators are divided based on the language model backend family they use. The backend family is defined by the API format and does not necessarily correspond to the language model architecture. For example, all backends that follow the OpenAI API format are groupped into \",[\"$\",\"em\",null,{\"children\":\"gpt\"}],\" family regardless the actual language model architecture or provider. Eeach backend family has its own set of estimators which are located in the \",[\"$\",\"code\",null,{\"children\":\"skllm.models.\u003cfamily\u003e\"}],\" sub-module.\"]}],[\"$\",\"p\",null,{\"children\":[\"For example, the Zero-Shot Classifier is available as \",[\"$\",\"code\",null,{\"children\":\"skllm.models.gpt.classification.zero_shot.ZeroShotGPTClassifier\"}],\" for the \",[\"$\",\"em\",null,{\"children\":\"gpt\"}],\" family, and as \",[\"$\",\"code\",null,{\"children\":\"skllm.models.vertex.classification.zero_shot.ZeroShotVertexClassifier\"}],\" for the \",[\"$\",\"em\",null,{\"children\":\"vertex\"}],\" family. The separation between the backend families is necessary to allow for a reasonable level of flexibility if/when model providers introduce model-specific features that are not supported by other providers and hence cannot be easily abstracted away. At the same time, the number of model families is kept to a minimum to simplify the usage and maintenance of the library. Since the OpenAI API is by far the most popular and widely used, backends that follow that format are preferred over the others.\"]}],[\"$\",\"p\",null,{\"children\":[\"Whenever the backend family supports multiple backends, the default one is used unless the \",[\"$\",\"code\",null,{\"children\":\"model\"}],\" parameter specifies a particular backend namespace. For example, the default backend for the \",[\"$\",\"em\",null,{\"children\":\"gpt\"}],\" family is the OpenAI backend. However, you can use the Azure backend by setting \",[\"$\",\"code\",null,{\"children\":\"model = \\\"azure::\u003cmodel_name\u003e\\\"\"}],\". However, please note that not every estimator supports every backend.\"]}],[\"$\",\"hr\",null,{}],[\"$\",\"h2\",null,{\"id\":\"gpt-family\",\"children\":\"GPT Family\"}],[\"$\",\"p\",null,{\"children\":\"The GPT family includes all backends that follow the OpenAI API format.\"}],[\"$\",\"h3\",null,{\"id\":\"open-ai-default\",\"children\":\"OpenAI (default)\"}],[\"$\",\"p\",null,{\"children\":[\"The OpenAI backend is the default backend for the GPT family. It is used whenever the \",[\"$\",\"code\",null,{\"children\":\"model\"}],\" parameter does not specify a particular backend namespace.\"]}],[\"$\",\"p\",null,{\"children\":\"To use the OpenAI backend, you need to set your OpenAI API key and organization ID as follows:\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skllm.config import SKLLMConfig\\n\\nSKLLMConfig.set_openai_key(\\\"\u003cYOUR_KEY\u003e\\\")\\nSKLLMConfig.set_openai_org(\\\"\u003cYOUR_ORGANIZATION_ID\u003e\\\")\\n\"}],[\"$\",\"h3\",null,{\"id\":\"azure\",\"children\":\"Azure\"}],[\"$\",\"p\",null,{\"children\":[\"OpenAI models can be alternatively used as a part of the \",[\"$\",\"a\",null,{\"href\":\"https://azure.microsoft.com/en-us/products/ai-services/openai-service\",\"children\":\"Azure OpenAI service\"}],\". To use the Azure backend, you need to provide your Azure API key and endpoint as follows:\"]}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skllm.config import SKLLMConfig\\n# Found under: Resource Management (Left Sidebar) -\u003e Keys and Endpoint -\u003e KEY 1\\nSKLLMConfig.set_gpt_key(\\\"\u003cYOUR_KEY\u003e\\\")\\n# Found under: Resource Management (Left Sidebar) -\u003e Keys and Endpoint -\u003e Endpoint\\nSKLLMConfig.set_azure_api_base(\\\"\u003cAPI_BASE\u003e\\\") # e.g. https://\u003cYOUR_PROJECT_NAME\u003e.openai.azure.com/\\n\"}],[\"$\",\"p\",null,{\"children\":[\"When using the Azure backend, the model should be specified as \",[\"$\",\"code\",null,{\"children\":\"model = \\\"azure::\u003cmodel_deployment_name\u003e\\\"\"}],\". For example, if you created a \",[\"$\",\"em\",null,{\"children\":\"gpt-3.5\"}],\" deployment under the name \",[\"$\",\"em\",null,{\"children\":\"my-model\"}],\", you should use \",[\"$\",\"code\",null,{\"children\":\"model = \\\"azure::my-model\\\"\"}],\".\"]}],[\"$\",\"h3\",null,{\"id\":\"gpt-4-all\",\"children\":\"GPT4ALL\"}],[\"$\",\"p\",null,{\"children\":\"GPT4ALL is an open-source library that provides a unified API for multiple small-scale language models, that can be run locally on a consumer-grade hardware, even without a GPU. To use the GPT4ALL backend, you need to install the corresponding extension as follows:\"}],[\"$\",\"$L10\",null,{\"language\":\"bash\",\"children\":\"pip install scikit-llm[gpt4all]\\n\"}],[\"$\",\"p\",null,{\"children\":[\"Then, you can use the GPT4ALL by specifying the model as \",[\"$\",\"code\",null,{\"children\":\"model = \\\"gpt4all::\u003cmodel_name\u003e\\\"\"}],\", which will be downloaded automatically. For the full list of available models, please refer to the \",[\"$\",\"a\",null,{\"href\":\"https://gpt4all.io/index.html\",\"children\":\"GPT4ALL official documentation\"}],\".\"]}],[\"$\",\"div\",null,{\"className\":\"my-8 flex rounded-3xl p-6 bg-amber-50 dark:bg-zinc-800/60 dark:ring-1 dark:ring-zinc-300/10\",\"children\":[[\"$\",\"svg\",null,{\"aria-hidden\":\"true\",\"viewBox\":\"0 0 32 32\",\"fill\":\"none\",\"className\":\"h-8 w-8 flex-none [--icon-foreground:theme(colors.zinc.900)] [--icon-background:theme(colors.white)]\",\"children\":[[\"$\",\"defs\",null,{\"children\":[[\"$\",\"radialGradient\",null,{\"cx\":0,\"cy\":0,\"r\":1,\"gradientUnits\":\"userSpaceOnUse\",\"id\":\":S1:-gradient\",\"gradientTransform\":\"matrix(0 21 -21 0 20 11)\",\"children\":[[\"$\",\"stop\",\"0\",{\"stopColor\":\"#F53803\"}],[\"$\",\"stop\",\"1\",{\"stopColor\":\"#FF7500\",\"offset\":\".527\"}],[\"$\",\"stop\",\"2\",{\"stopColor\":\"#FDBA74\",\"offset\":1}]]}],[\"$\",\"radialGradient\",null,{\"cx\":0,\"cy\":0,\"r\":1,\"gradientUnits\":\"userSpaceOnUse\",\"id\":\":S1:-gradient-dark\",\"gradientTransform\":\"matrix(0 24.5001 -19.2498 0 16 5.5)\",\"children\":[[\"$\",\"stop\",\"0\",{\"stopColor\":\"#F53803\"}],[\"$\",\"stop\",\"1\",{\"stopColor\":\"#FF7500\",\"offset\":\".527\"}],[\"$\",\"stop\",\"2\",{\"stopColor\":\"#FDBA74\",\"offset\":1}]]}]]}],[\"$\",\"g\",null,{\"className\":\"dark:hidden\",\"children\":[[\"$\",\"circle\",null,{\"cx\":20,\"cy\":20,\"r\":12,\"fill\":\"url(#:S1:-gradient)\"}],[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M20 24.995c0-1.855 1.094-3.501 2.427-4.792C24.61 18.087 26 15.07 26 12.231 26 7.133 21.523 3 16 3S6 7.133 6 12.23c0 2.84 1.389 5.857 3.573 7.973C10.906 21.494 12 23.14 12 24.995V27a2 2 0 0 0 2 2h4a2 2 0 0 0 2-2v-2.005Z\",\"className\":\"fill-[var(--icon-background)]\",\"fillOpacity\":0.5}],[\"$\",\"path\",null,{\"d\":\"M25 12.23c0 2.536-1.254 5.303-3.269 7.255l1.391 1.436c2.354-2.28 3.878-5.547 3.878-8.69h-2ZM16 4c5.047 0 9 3.759 9 8.23h2C27 6.508 21.998 2 16 2v2Zm-9 8.23C7 7.76 10.953 4 16 4V2C10.002 2 5 6.507 5 12.23h2Zm3.269 7.255C8.254 17.533 7 14.766 7 12.23H5c0 3.143 1.523 6.41 3.877 8.69l1.392-1.436ZM13 27v-2.005h-2V27h2Zm1 1a1 1 0 0 1-1-1h-2a3 3 0 0 0 3 3v-2Zm4 0h-4v2h4v-2Zm1-1a1 1 0 0 1-1 1v2a3 3 0 0 0 3-3h-2Zm0-2.005V27h2v-2.005h-2ZM8.877 20.921C10.132 22.136 11 23.538 11 24.995h2c0-2.253-1.32-4.143-2.731-5.51L8.877 20.92Zm12.854-1.436C20.32 20.852 19 22.742 19 24.995h2c0-1.457.869-2.859 2.122-4.074l-1.391-1.436Z\",\"className\":\"fill-[var(--icon-foreground)]\"}],[\"$\",\"path\",null,{\"d\":\"M20 26a1 1 0 1 0 0-2v2Zm-8-2a1 1 0 1 0 0 2v-2Zm2 0h-2v2h2v-2Zm1 1V13.5h-2V25h2Zm-5-11.5v1h2v-1h-2Zm3.5 4.5h5v-2h-5v2Zm8.5-3.5v-1h-2v1h2ZM20 24h-2v2h2v-2Zm-2 0h-4v2h4v-2Zm-1-10.5V25h2V13.5h-2Zm2.5-2.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2ZM18.5 18a3.5 3.5 0 0 0 3.5-3.5h-2a1.5 1.5 0 0 1-1.5 1.5v2ZM10 14.5a3.5 3.5 0 0 0 3.5 3.5v-2a1.5 1.5 0 0 1-1.5-1.5h-2Zm2.5-3.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2Z\",\"className\":\"fill-[var(--icon-foreground)]\"}]]}],[\"$\",\"g\",null,{\"className\":\"hidden dark:inline\",\"children\":[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M16 2C10.002 2 5 6.507 5 12.23c0 3.144 1.523 6.411 3.877 8.691.75.727 1.363 1.52 1.734 2.353.185.415.574.726 1.028.726H12a1 1 0 0 0 1-1v-4.5a.5.5 0 0 0-.5-.5A3.5 3.5 0 0 1 9 14.5V14a3 3 0 1 1 6 0v9a1 1 0 1 0 2 0v-9a3 3 0 1 1 6 0v.5a3.5 3.5 0 0 1-3.5 3.5.5.5 0 0 0-.5.5V23a1 1 0 0 0 1 1h.36c.455 0 .844-.311 1.03-.726.37-.833.982-1.626 1.732-2.353 2.354-2.28 3.878-5.547 3.878-8.69C27 6.507 21.998 2 16 2Zm5 25a1 1 0 0 0-1-1h-8a1 1 0 0 0-1 1 3 3 0 0 0 3 3h4a3 3 0 0 0 3-3Zm-8-13v1.5a.5.5 0 0 1-.5.5 1.5 1.5 0 0 1-1.5-1.5V14a1 1 0 1 1 2 0Zm6.5 2a.5.5 0 0 1-.5-.5V14a1 1 0 1 1 2 0v.5a1.5 1.5 0 0 1-1.5 1.5Z\",\"fill\":\"url(#:S1:-gradient-dark)\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"ml-4 flex-auto\",\"children\":[[\"$\",\"p\",null,{\"className\":\"m-0 font-display text-xl text-amber-900 dark:text-amber-500\",\"children\":\"Note\"}],[\"$\",\"div\",null,{\"className\":\"prose mt-2.5 text-amber-800 [--tw-prose-underline:theme(colors.amber.400)] [--tw-prose-background:theme(colors.amber.50)] prose-a:text-amber-900 prose-code:text-amber-900 dark:text-zinc-300 dark:[--tw-prose-underline:theme(colors.amber.700)] dark:prose-code:text-zinc-300\",\"children\":[\"$\",\"p\",null,{\"children\":\"The models available through the GPT4ALL out of the box have very limited capabilities and are not recommended for most of the use cases. In addition, not all models are permitted for commercial use. Please check the license of the model you are using before deploying it in production.\"}]}]]}]]}],[\"$\",\"h3\",null,{\"id\":\"custom-url\",\"children\":\"Custom URL\"}],[\"$\",\"p\",null,{\"children\":\"Custom URL backend allows to use any GPT estimator with any OpenAI-compatible provider (either running locally or in the cloud).\"}],[\"$\",\"p\",null,{\"children\":\"In order to use the backend, it is necessary to set a global custom url:\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skllm.config import SKLLMConfig\\n\\nSKLLMConfig.set_gpt_url(\\\"http://localhost:8000/\\\")\\n\\nclf = ZeroShotGPTClassifier(model=\\\"custom_url::\u003ccustom_model_name\u003e\\\")\\n\"}],[\"$\",\"div\",null,{\"className\":\"my-8 flex rounded-3xl p-6 bg-amber-50 dark:bg-zinc-800/60 dark:ring-1 dark:ring-zinc-300/10\",\"children\":[[\"$\",\"svg\",null,{\"aria-hidden\":\"true\",\"viewBox\":\"0 0 32 32\",\"fill\":\"none\",\"className\":\"h-8 w-8 flex-none [--icon-foreground:theme(colors.zinc.900)] [--icon-background:theme(colors.white)]\",\"children\":[[\"$\",\"defs\",null,{\"children\":[[\"$\",\"radialGradient\",null,{\"cx\":0,\"cy\":0,\"r\":1,\"gradientUnits\":\"userSpaceOnUse\",\"id\":\":S2:-gradient\",\"gradientTransform\":\"matrix(0 21 -21 0 20 11)\",\"children\":[[\"$\",\"stop\",\"0\",{\"stopColor\":\"#F53803\"}],[\"$\",\"stop\",\"1\",{\"stopColor\":\"#FF7500\",\"offset\":\".527\"}],[\"$\",\"stop\",\"2\",{\"stopColor\":\"#FDBA74\",\"offset\":1}]]}],[\"$\",\"radialGradient\",null,{\"cx\":0,\"cy\":0,\"r\":1,\"gradientUnits\":\"userSpaceOnUse\",\"id\":\":S2:-gradient-dark\",\"gradientTransform\":\"matrix(0 24.5001 -19.2498 0 16 5.5)\",\"children\":[[\"$\",\"stop\",\"0\",{\"stopColor\":\"#F53803\"}],[\"$\",\"stop\",\"1\",{\"stopColor\":\"#FF7500\",\"offset\":\".527\"}],[\"$\",\"stop\",\"2\",{\"stopColor\":\"#FDBA74\",\"offset\":1}]]}]]}],[\"$\",\"g\",null,{\"className\":\"dark:hidden\",\"children\":[[\"$\",\"circle\",null,{\"cx\":20,\"cy\":20,\"r\":12,\"fill\":\"url(#:S2:-gradient)\"}],[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M20 24.995c0-1.855 1.094-3.501 2.427-4.792C24.61 18.087 26 15.07 26 12.231 26 7.133 21.523 3 16 3S6 7.133 6 12.23c0 2.84 1.389 5.857 3.573 7.973C10.906 21.494 12 23.14 12 24.995V27a2 2 0 0 0 2 2h4a2 2 0 0 0 2-2v-2.005Z\",\"className\":\"fill-[var(--icon-background)]\",\"fillOpacity\":0.5}],[\"$\",\"path\",null,{\"d\":\"M25 12.23c0 2.536-1.254 5.303-3.269 7.255l1.391 1.436c2.354-2.28 3.878-5.547 3.878-8.69h-2ZM16 4c5.047 0 9 3.759 9 8.23h2C27 6.508 21.998 2 16 2v2Zm-9 8.23C7 7.76 10.953 4 16 4V2C10.002 2 5 6.507 5 12.23h2Zm3.269 7.255C8.254 17.533 7 14.766 7 12.23H5c0 3.143 1.523 6.41 3.877 8.69l1.392-1.436ZM13 27v-2.005h-2V27h2Zm1 1a1 1 0 0 1-1-1h-2a3 3 0 0 0 3 3v-2Zm4 0h-4v2h4v-2Zm1-1a1 1 0 0 1-1 1v2a3 3 0 0 0 3-3h-2Zm0-2.005V27h2v-2.005h-2ZM8.877 20.921C10.132 22.136 11 23.538 11 24.995h2c0-2.253-1.32-4.143-2.731-5.51L8.877 20.92Zm12.854-1.436C20.32 20.852 19 22.742 19 24.995h2c0-1.457.869-2.859 2.122-4.074l-1.391-1.436Z\",\"className\":\"fill-[var(--icon-foreground)]\"}],[\"$\",\"path\",null,{\"d\":\"M20 26a1 1 0 1 0 0-2v2Zm-8-2a1 1 0 1 0 0 2v-2Zm2 0h-2v2h2v-2Zm1 1V13.5h-2V25h2Zm-5-11.5v1h2v-1h-2Zm3.5 4.5h5v-2h-5v2Zm8.5-3.5v-1h-2v1h2ZM20 24h-2v2h2v-2Zm-2 0h-4v2h4v-2Zm-1-10.5V25h2V13.5h-2Zm2.5-2.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2ZM18.5 18a3.5 3.5 0 0 0 3.5-3.5h-2a1.5 1.5 0 0 1-1.5 1.5v2ZM10 14.5a3.5 3.5 0 0 0 3.5 3.5v-2a1.5 1.5 0 0 1-1.5-1.5h-2Zm2.5-3.5a2.5 2.5 0 0 0-2.5 2.5h2a.5.5 0 0 1 .5-.5v-2Zm2.5 2.5a2.5 2.5 0 0 0-2.5-2.5v2a.5.5 0 0 1 .5.5h2Z\",\"className\":\"fill-[var(--icon-foreground)]\"}]]}],[\"$\",\"g\",null,{\"className\":\"hidden dark:inline\",\"children\":[\"$\",\"path\",null,{\"fillRule\":\"evenodd\",\"clipRule\":\"evenodd\",\"d\":\"M16 2C10.002 2 5 6.507 5 12.23c0 3.144 1.523 6.411 3.877 8.691.75.727 1.363 1.52 1.734 2.353.185.415.574.726 1.028.726H12a1 1 0 0 0 1-1v-4.5a.5.5 0 0 0-.5-.5A3.5 3.5 0 0 1 9 14.5V14a3 3 0 1 1 6 0v9a1 1 0 1 0 2 0v-9a3 3 0 1 1 6 0v.5a3.5 3.5 0 0 1-3.5 3.5.5.5 0 0 0-.5.5V23a1 1 0 0 0 1 1h.36c.455 0 .844-.311 1.03-.726.37-.833.982-1.626 1.732-2.353 2.354-2.28 3.878-5.547 3.878-8.69C27 6.507 21.998 2 16 2Zm5 25a1 1 0 0 0-1-1h-8a1 1 0 0 0-1 1 3 3 0 0 0 3 3h4a3 3 0 0 0 3-3Zm-8-13v1.5a.5.5 0 0 1-.5.5 1.5 1.5 0 0 1-1.5-1.5V14a1 1 0 1 1 2 0Zm6.5 2a.5.5 0 0 1-.5-.5V14a1 1 0 1 1 2 0v.5a1.5 1.5 0 0 1-1.5 1.5Z\",\"fill\":\"url(#:S2:-gradient-dark)\"}]}]]}],[\"$\",\"div\",null,{\"className\":\"ml-4 flex-auto\",\"children\":[[\"$\",\"p\",null,{\"className\":\"m-0 font-display text-xl text-amber-900 dark:text-amber-500\",\"children\":\"Note\"}],[\"$\",\"div\",null,{\"className\":\"prose mt-2.5 text-amber-800 [--tw-prose-underline:theme(colors.amber.400)] [--tw-prose-background:theme(colors.amber.50)] prose-a:text-amber-900 prose-code:text-amber-900 dark:text-zinc-300 dark:[--tw-prose-underline:theme(colors.amber.700)] dark:prose-code:text-zinc-300\",\"children\":[\"$\",\"p\",null,{\"children\":[\"When using \",[\"$\",\"code\",null,{\"children\":\"custom_url\"}],\" and \",[\"$\",\"code\",null,{\"children\":\"openai\"}],\" backends within the same script, it is necessary to reset the custom url configuration using \",[\"$\",\"code\",null,{\"children\":\"SKLLMConfig.reset_gpt_url()\"}],\".\"]}]}]]}]]}],[\"$\",\"hr\",null,{}],[\"$\",\"h2\",null,{\"id\":\"vertex-family\",\"children\":\"Vertex Family\"}],[\"$\",\"p\",null,{\"children\":\"The Vertex family currently includes a single (default) backend, which is the Google Vertex AI.\"}],[\"$\",\"p\",null,{\"children\":\"In order to use the Vertex backend, you need to configure your Google Cloud credentials as follows:\"}],[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"p\",null,{\"children\":[\"Log in to \",[\"$\",\"a\",null,{\"href\":\"https://console.cloud.google.com/\",\"children\":\"Google Cloud Console\"}],\" and \",[\"$\",\"a\",null,{\"href\":\"https://developers.google.com/workspace/guides/create-project\",\"children\":\"create a Google Cloud project\"}],\". After the project is created, select this project from a list of projects next to the Google Cloud logo (upper left corner).\"]}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"p\",null,{\"children\":[\"Search for \",[\"$\",\"em\",null,{\"children\":\"Vertex AI\"}],\" in the search bar and select it from the list of services.\"]}]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":[\"Install a Google Cloud CLI on the local machine by following \",[\"$\",\"a\",null,{\"href\":\"https://cloud.google.com/sdk/docs/install\",\"children\":\"the steps from the official documentation\"}],\", and \",[\"$\",\"a\",null,{\"href\":\"https://cloud.google.com/docs/authentication/application-default-credentials#personal\",\"children\":\"set the application default credentials\"}],\" by running the following command:\"]}],[\"$\",\"$L10\",null,{\"language\":\"bash\",\"children\":\"gcloud auth application-default login\\n\"}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":\"Configure Scikit-LLM with your project ID:\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skllm.config import SKLLMConfig\\n\\nSKLLMConfig.set_google_project(\\\"\u003cYOUR_PROJECT_ID\u003e\\\")\\n\"}]]}]]}],[\"$\",\"p\",null,{\"children\":\"Additionally, for tuning LLMs in Vertex, it is required to have to have 64 cores of the TPU v3 pod training resource. By default this quota is set to 0 cores and has to be increased as follows (ignore this if you are not planning to use the tunable estimators):\"}],[\"$\",\"ol\",null,{\"children\":[[\"$\",\"li\",null,{\"children\":[\"Go to \",[\"$\",\"a\",null,{\"href\":\"https://cloud.google.com/docs/quota/view-manage#requesting_higher_quota\",\"children\":\"Quotas\"}],\" and filter them for “Restricted image training TPU V3 pod cores per region”.\"]}],[\"$\",\"li\",null,{\"children\":\"Select “europe-west4” region (currently this is the only supported region).\"}],[\"$\",\"li\",null,{\"children\":[\"Click on “Edit Quotas”, set the limit to 64 and submit the request.\",\" \",\"The request should be approved within a few hours, but it might take up to several days.\"]}]]}]]}]]}],[\"$\",\"$L11\",null,{}]]}],[\"$\",\"$L12\",null,{\"tableOfContents\":[{\"level\":2,\"id\":\"gpt-family\",\"title\":\"GPT Family\",\"children\":[{\"level\":3,\"id\":\"open-ai-default\",\"title\":\"OpenAI (default)\"},{\"level\":3,\"id\":\"azure\",\"title\":\"Azure\"},{\"level\":3,\"id\":\"gpt-4-all\",\"title\":\"GPT4ALL\"},{\"level\":3,\"id\":\"custom-url\",\"title\":\"Custom URL\"}]},{\"level\":2,\"id\":\"vertex-family\",\"title\":\"Vertex Family\",\"children\":[]}]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Backend families - Docs\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Overview of backend families.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/bayreuth_ai_association/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>