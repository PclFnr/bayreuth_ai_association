<!DOCTYPE html><html lang="en" class="h-full antialiased __variable_01f60e __variable_a0637f"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/bayreuth_ai_association/_next/static/media/8935352d0bfcf3a9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/bayreuth_ai_association/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/bayreuth_ai_association/_next/static/chunks/webpack-ce4d567c9f2a94d3.js"/><script src="/bayreuth_ai_association/_next/static/chunks/fd9d1056-96f96ef28edce221.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/23-80ca076b01c7bb1f.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/main-app-28cdedace4fab0f2.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/231-829f56fdb7c75283.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/55-c141fc066ff4a19d.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/472-cd817ab664ce0632.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/app/layout-1cfcfb656b6cf4a5.js" async=""></script><script src="/bayreuth_ai_association/_next/static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js" async=""></script><title>Text vectorization - Docs</title><meta name="description" content="Learn about text vectorization."/><link rel="icon" href="/bayreuth_ai_association/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/bayreuth_ai_association/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="flex min-h-full bg-white dark:bg-zinc-900"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="flex w-full flex-col"><header class="sticky top-0 z-50 flex flex-none flex-wrap items-center justify-between bg-white px-4 py-5 shadow-md shadow-zinc-900/5 transition duration-500 sm:px-6 lg:px-8 dark:shadow-none dark:bg-transparent"><div class="mr-6 flex lg:hidden"><button type="button" class="relative" aria-label="Open navigation"><svg aria-hidden="true" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke-linecap="round" class="h-6 w-6 stroke-zinc-500"><path d="M4 7h16M4 12h16M4 17h16"></path></svg></button><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div></div><div class="relative flex flex-grow basis-0 items-center"><a aria-label="Home page" href="/bayreuth_ai_association"><p>scikit-ollama</p></a></div><div class="-my-5 mr-6 sm:mr-8 md:mr-0"><button type="button" class="group flex h-6 w-6 items-center justify-center sm:justify-start md:h-auto md:w-80 md:flex-none md:rounded-lg md:py-2.5 md:pl-4 md:pr-3.5 md:text-sm md:ring-1 md:ring-zinc-200 md:hover:ring-zinc-300 lg:w-96 dark:md:bg-zinc-800/75 dark:md:ring-inset dark:md:ring-white/5 dark:md:hover:bg-zinc-700/40 dark:md:hover:ring-zinc-500"><svg aria-hidden="true" viewBox="0 0 20 20" class="h-5 w-5 flex-none fill-zinc-400 group-hover:fill-zinc-500 md:group-hover:fill-zinc-400 dark:fill-zinc-500"><path d="M16.293 17.707a1 1 0 0 0 1.414-1.414l-1.414 1.414ZM9 14a5 5 0 0 1-5-5H2a7 7 0 0 0 7 7v-2ZM4 9a5 5 0 0 1 5-5V2a7 7 0 0 0-7 7h2Zm5-5a5 5 0 0 1 5 5h2a7 7 0 0 0-7-7v2Zm8.707 12.293-3.757-3.757-1.414 1.414 3.757 3.757 1.414-1.414ZM14 9a4.98 4.98 0 0 1-1.464 3.536l1.414 1.414A6.98 6.98 0 0 0 16 9h-2Zm-1.464 3.536A4.98 4.98 0 0 1 9 14v2a6.98 6.98 0 0 0 4.95-2.05l-1.414-1.414Z"></path></svg><span class="sr-only md:not-sr-only md:ml-2 md:text-zinc-500 md:dark:text-zinc-400">Search docs</span></button><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div></div><div class="relative flex basis-0 justify-end gap-6 sm:gap-8 md:flex-grow"><div class="h-6 w-6"></div><a class="group" aria-label="GitHub" href="https://github.com/AndreasKarasenko/scikit-ollama"><svg aria-hidden="true" viewBox="0 0 16 16" class="h-6 w-6 fill-zinc-400 group-hover:fill-zinc-500 dark:group-hover:fill-zinc-300"><path d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z"></path></svg></a></div></header><div id="cde"></div><div class="relative mx-auto flex w-full max-w-8xl flex-auto justify-center sm:px-2 lg:px-8 xl:px-12"><div class="hidden lg:relative lg:block lg:flex-none"><div class="absolute inset-y-0 right-0 w-[50vw] bg-zinc-50 dark:hidden"></div><div class="absolute bottom-0 right-0 top-16 hidden h-12 w-px bg-gradient-to-t from-zinc-800 dark:block"></div><div class="absolute bottom-0 right-0 top-28 hidden w-px bg-zinc-800 dark:block"></div><div class="sticky top-[4.75rem] -ml-0.5 h-[calc(100vh-4.75rem)] w-64 overflow-y-auto overflow-x-hidden py-16 pl-0.5 pr-8 xl:w-72 xl:pr-16"><nav class="text-base lg:text-sm"><ul role="list" class="space-y-9"><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Introduction</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association">Home</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/about-our-meetings">About our meetings</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Text classification</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/zero-shot-text-classification">Zero-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/few-shot-text-classification">Few-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/dynamic-few-shot-text-classification">Dynamic few-shot text classification</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/tunable-text-classification">Tunable text classification</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Text-to-text modelling</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/text-summarization">Text summarization</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/text-translation">Text translation</a></li><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/tunable-text-to-text">Tunable text-to-text</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Resources</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full font-semibold text-teal-500 before:bg-teal-500 dark:text-teal-200" href="/bayreuth_ai_association/docs/text-vectorization">Overview</a></li></ul></li><li><h2 class="font-display font-medium text-zinc-900 dark:text-white">Contributing</h2><ul role="list" class="mt-2 space-y-2 border-l-2 border-zinc-100 lg:mt-4 lg:space-y-4 lg:border-zinc-200 dark:border-zinc-800"><li class="relative"><a class="block w-full pl-3.5 before:pointer-events-none before:absolute before:-left-1 before:top-1/2 before:h-1.5 before:w-1.5 before:-translate-y-1/2 before:rounded-full text-zinc-500 before:hidden before:bg-zinc-300 hover:text-zinc-600 hover:before:block dark:text-zinc-400 dark:before:bg-zinc-700 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/how-to-contribute">How to contribute</a></li></ul></li></ul></nav></div></div><div class="min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16"><article><header class="mb-9 space-y-1"><p class="font-display text-sm font-medium text-teal-800 dark:text-teal-200">Resources</p><h1 class="font-display text-3xl tracking-tight text-zinc-900 dark:text-white">Text vectorization</h1></header><div class="prose prose-teal max-w-none dark:prose-invert dark:text-teal-200 prose-headings:scroll-mt-28 prose-headings:font-display prose-headings:font-normal lg:prose-headings:scroll-mt-[8.5rem] prose-lead:text-teal-500 dark:prose-lead:text-teal-400 prose-a:font-semibold dark:prose-a:text-teal-400 prose-a:no-underline prose-a:shadow-[inset_0_-2px_0_0_var(--tw-prose-background,#fff),inset_0_calc(-1*(var(--tw-prose-underline-size,4px)+2px))_0_0_var(--tw-prose-underline,theme(colors.teal.300))] hover:prose-a:[--tw-prose-underline-size:6px] dark:[--tw-prose-background:theme(colors.teal.900)] dark:prose-a:shadow-[inset_0_calc(-1*var(--tw-prose-underline-size,2px))_0_0_var(--tw-prose-underline,theme(colors.teal.800))] dark:hover:prose-a:[--tw-prose-underline-size:6px] prose-pre:rounded-xl prose-pre:bg-zinc-900 prose-pre:shadow-lg dark:prose-pre:bg-zinc-700/40 dark:prose-pre:shadow-none dark:prose-pre:ring-1 dark:prose-pre:ring-zinc-100/10 dark:prose-hr:border-teal-800"><h2 id="overview">Overview</h2><p>LLMs can be used solely for data preprocessing by embedding a chunk of text of arbitrary length to a fixed-dimensional vector, that can be further used with virtually any model (e.g. classification, regression, clustering, etc.).</p><p>With Scikit-Ollama you can choose from a large variety of embedding models. The quality of which you can check on leaderboards such as Huggingface&#x27;s <a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB</a>. In the following example we will work with the default <code>nomic-embed-text</code> embedding model. Simply download it using the usual Ollama CLI command:</p><pre class="prism-code language-bash" style="color:#e4e4e7;font-style:normal"><code><span class="token plain">ollama pull nomic-embed-text</span>
</code></pre><p>Example 1: Embedding the text</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skollama</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">models</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">ollama</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">vectorization </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> OllamaVectorizer</span>
<!-- -->
<span class="token plain">vectorizer </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> OllamaVectorizer</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">batch_size</span><span class="token operator" style="color:#a1a1aa">=</span><span class="token number" style="color:#fdba74">2</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a9955"># batch_size is number of parallel tasks</span><span class="token plain"></span>
<span class="token plain">X </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token punctuation" style="color:#a1a1aa">[</span><span class="token string" style="color:#fdba74">&quot;This is a text&quot;</span><span class="token punctuation" style="color:#a1a1aa">,</span><span class="token plain"> </span><span class="token string" style="color:#fdba74">&quot;This is another text&quot;</span><span class="token punctuation" style="color:#a1a1aa">]</span><span class="token punctuation" style="color:#a1a1aa">)</span>
</code></pre><p>Example 2: Combining the vectorizer with the XGBoost classifier in a scikit-learn pipeline</p><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">pipeline </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> Pipeline</span>
<span class="token plain"></span><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">preprocessing </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> LabelEncoder</span>
<span class="token plain"></span><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> xgboost </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> XGBClassifier</span>
<!-- -->
<span class="token plain">le </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> LabelEncoder</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain">y_train_encoded </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> le</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">y_train</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain">y_test_encoded </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> le</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">y_test</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<!-- -->
<span class="token plain">steps </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#a1a1aa">[</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;Ollama&quot;</span><span class="token punctuation" style="color:#a1a1aa">,</span><span class="token plain"> OllamaVectorizer</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token punctuation" style="color:#a1a1aa">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token string" style="color:#fdba74">&quot;Clf&quot;</span><span class="token punctuation" style="color:#a1a1aa">,</span><span class="token plain"> XGBClassifier</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token punctuation" style="color:#a1a1aa">]</span><span class="token plain"></span>
<span class="token plain">clf </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> Pipeline</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">steps</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain">clf</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">X_train</span><span class="token punctuation" style="color:#a1a1aa">,</span><span class="token plain"> y_train_encoded</span><span class="token punctuation" style="color:#a1a1aa">)</span><span class="token plain"></span>
<span class="token plain">yh </span><span class="token operator" style="color:#a1a1aa">=</span><span class="token plain"> clf</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#a1a1aa">(</span><span class="token plain">X_test</span><span class="token punctuation" style="color:#a1a1aa">)</span>
</code></pre><hr/><h2 id="api-reference">API Reference</h2><p>The following API reference only lists the parameters needed for the initialization of the estimator. The remaining methods follow the syntax of a scikit-learn transformer.</p><h3 id="ollama-vectorizer">OllamaVectorizer</h3><pre class="prism-code language-python" style="color:#e4e4e7;font-style:normal"><code><span class="token keyword" style="color:#ff7500">from</span><span class="token plain"> skllm</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">models</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">gpt</span><span class="token punctuation" style="color:#a1a1aa">.</span><span class="token plain">vectorization </span><span class="token keyword" style="color:#ff7500">import</span><span class="token plain"> OllamaVectorizer</span>
</code></pre><table><thead><tr><th scope="col"><strong>Parameter</strong></th><th scope="col"><strong>Type</strong></th><th scope="col"><strong>Description</strong></th></tr></thead><tbody><tr><td><code>model</code></td><td><code>str</code></td><td>Model to use, by default &quot;text-embedding-3-small&quot;.</td></tr><tr><td><code>batch_size</code></td><td><code>int</code></td><td>Number of samples per request, by default 1.</td></tr><tr><td><code>key</code></td><td><code>Optional[str]</code></td><td>Estimator-specific API key; if None, retrieved from the global config, by default None.</td></tr><tr><td><code>org</code></td><td><code>Optional[str]</code></td><td>Estimator-specific ORG key; if None, retrieved from the global config, by default None.</td></tr></tbody></table></div></article><dl class="mt-12 flex border-t border-zinc-200 pt-6 dark:border-zinc-800"><div><dt class="font-display text-sm font-medium text-zinc-900 dark:text-white">Previous</dt><dd class="mt-1"><a class="flex items-center gap-x-1 text-base font-semibold text-zinc-500 hover:text-zinc-600 dark:text-zinc-400 dark:hover:text-zinc-300 flex-row-reverse" href="/bayreuth_ai_association/docs/tunable-text-to-text">Tunable text-to-text<svg viewBox="0 0 16 16" aria-hidden="true" class="h-4 w-4 flex-none fill-current -scale-x-100"><path d="m9.182 13.423-1.17-1.16 3.505-3.505H3V7.065h8.517l-3.506-3.5L9.181 2.4l5.512 5.511-5.511 5.512Z"></path></svg></a></dd></div><div class="ml-auto text-right"><dt class="font-display text-sm font-medium text-zinc-900 dark:text-white">Next</dt><dd class="mt-1"><a class="flex items-center gap-x-1 text-base font-semibold text-zinc-500 hover:text-zinc-600 dark:text-zinc-400 dark:hover:text-zinc-300" href="/bayreuth_ai_association/docs/how-to-contribute">How to contribute<svg viewBox="0 0 16 16" aria-hidden="true" class="h-4 w-4 flex-none fill-current"><path d="m9.182 13.423-1.17-1.16 3.505-3.505H3V7.065h8.517l-3.506-3.5L9.181 2.4l5.512 5.511-5.511 5.512Z"></path></svg></a></dd></div></dl></div><div class="hidden xl:sticky xl:top-[4.75rem] xl:-mr-6 xl:block xl:h-[calc(100vh-4.75rem)] xl:flex-none xl:overflow-y-auto xl:py-16 xl:pr-6"><nav aria-labelledby="on-this-page-title" class="w-56"><h2 id="on-this-page-title" class="font-display text-sm font-medium text-zinc-900 dark:text-white">On this page</h2><ol role="list" class="mt-4 space-y-3 text-sm"><li><h3><a class="text-teal-500 dark:text-teal-200" href="#overview">Overview</a></h3></li><li><h3><a class="font-normal text-zinc-500 hover:text-zinc-600 dark:text-zinc-400 dark:hover:text-zinc-300" href="#api-reference">API Reference</a></h3><ol role="list" class="mt-2 space-y-3 pl-5 text-zinc-500 dark:text-zinc-400"><li><a class="hover:text-zinc-600 dark:hover:text-zinc-300" href="#ollama-vectorizer">OllamaVectorizer</a></li></ol></li></ol></nav></div></div></div><script src="/bayreuth_ai_association/_next/static/chunks/webpack-ce4d567c9f2a94d3.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/bayreuth_ai_association/_next/static/media/8935352d0bfcf3a9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/bayreuth_ai_association/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n7:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[1747,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"472\",\"static/chunks/472-cd817ab664ce0632.js\",\"185\",\"static/chunks/app/layout-1cfcfb656b6cf4a5.js\"],\"Providers\"]\na:I[1227,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"472\",\"static/chunks/472-cd817ab664ce0632.js\",\"185\",\"static/chunks/app/layout-1cfcfb656b6cf4a5.js\"],\"Layout\"]\nb:I[231,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"326\",\"static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js\"],\"\"]\nd:I[6130,[],\"\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/bayreuth_ai_association/_next/static/css/c6750efcaf6fd8ff.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"KteObhGWKN4CvpFO1QXQU\",\"assetPrefix\":\"/bayreuth_ai_association\",\"initialCanonicalUrl\":\"/docs/text-vectorization\",\"initialTree\":[\"\",{\"children\":[\"docs\",{\"children\":[\"text-vectorization\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"docs\",{\"children\":[\"text-vectorization\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",\"$L6\"],null],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"docs\",\"children\",\"text-vectorization\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"docs\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"h-full antialiased __variable_01f60e __variable_a0637f\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"flex min-h-full bg-white dark:bg-zinc-900\",\"children\":[\"$\",\"$L9\",null,{\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex h-full flex-col items-center justify-center text-center\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-display text-sm font-medium text-zinc-900 dark:text-white\",\"children\":\"404\"}],[\"$\",\"h1\",null,{\"className\":\"mt-3 font-display text-3xl tracking-tight text-zinc-900 dark:text-white\",\"children\":\"Page not found\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-sm text-zinc-500 dark:text-zinc-400\",\"children\":\"Sorry, we couldn’t find the page you’re looking for.\"}],[\"$\",\"$Lb\",null,{\"href\":\"/\",\"className\":\"mt-8 text-sm font-medium text-zinc-900 dark:text-white\",\"children\":\"Go back home\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]]\n"])</script><script>self.__next_f.push([1,"f:I[4456,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"326\",\"static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js\"],\"DocsHeader\"]\n10:I[7408,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"326\",\"static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js\"],\"Fence\"]\n11:I[2553,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"326\",\"static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js\"],\"PrevNextLinks\"]\n12:I[817,[\"231\",\"static/chunks/231-829f56fdb7c75283.js\",\"55\",\"static/chunks/55-c141fc066ff4a19d.js\",\"326\",\"static/chunks/app/docs/text-vectorization/page-e707a883c88688af.js\"],\"TableOfContents\"]\n"])</script><script>self.__next_f.push([1,"6:[[\"$\",\"div\",null,{\"className\":\"min-w-0 max-w-2xl flex-auto px-4 py-16 lg:max-w-none lg:pl-8 lg:pr-0 xl:px-16\",\"children\":[[\"$\",\"article\",null,{\"children\":[[\"$\",\"$Lf\",null,{\"title\":\"Text vectorization\"}],[\"$\",\"div\",null,{\"className\":\"prose prose-teal max-w-none dark:prose-invert dark:text-teal-200 prose-headings:scroll-mt-28 prose-headings:font-display prose-headings:font-normal lg:prose-headings:scroll-mt-[8.5rem] prose-lead:text-teal-500 dark:prose-lead:text-teal-400 prose-a:font-semibold dark:prose-a:text-teal-400 prose-a:no-underline prose-a:shadow-[inset_0_-2px_0_0_var(--tw-prose-background,#fff),inset_0_calc(-1*(var(--tw-prose-underline-size,4px)+2px))_0_0_var(--tw-prose-underline,theme(colors.teal.300))] hover:prose-a:[--tw-prose-underline-size:6px] dark:[--tw-prose-background:theme(colors.teal.900)] dark:prose-a:shadow-[inset_0_calc(-1*var(--tw-prose-underline-size,2px))_0_0_var(--tw-prose-underline,theme(colors.teal.800))] dark:hover:prose-a:[--tw-prose-underline-size:6px] prose-pre:rounded-xl prose-pre:bg-zinc-900 prose-pre:shadow-lg dark:prose-pre:bg-zinc-700/40 dark:prose-pre:shadow-none dark:prose-pre:ring-1 dark:prose-pre:ring-zinc-100/10 dark:prose-hr:border-teal-800\",\"children\":[[\"$\",\"h2\",null,{\"id\":\"overview\",\"children\":\"Overview\"}],[\"$\",\"p\",null,{\"children\":\"LLMs can be used solely for data preprocessing by embedding a chunk of text of arbitrary length to a fixed-dimensional vector, that can be further used with virtually any model (e.g. classification, regression, clustering, etc.).\"}],[\"$\",\"p\",null,{\"children\":[\"With Scikit-Ollama you can choose from a large variety of embedding models. The quality of which you can check on leaderboards such as Huggingface's \",[\"$\",\"a\",null,{\"href\":\"https://huggingface.co/spaces/mteb/leaderboard\",\"children\":\"MTEB\"}],\". In the following example we will work with the default \",[\"$\",\"code\",null,{\"children\":\"nomic-embed-text\"}],\" embedding model. Simply download it using the usual Ollama CLI command:\"]}],[\"$\",\"$L10\",null,{\"language\":\"bash\",\"children\":\"ollama pull nomic-embed-text\\n\"}],[\"$\",\"p\",null,{\"children\":\"Example 1: Embedding the text\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skollama.models.ollama.vectorization import OllamaVectorizer\\n\\nvectorizer = OllamaVectorizer(batch_size=2) # batch_size is number of parallel tasks\\nX = vectorizer.fit_transform([\\\"This is a text\\\", \\\"This is another text\\\"])\\n\"}],[\"$\",\"p\",null,{\"children\":\"Example 2: Combining the vectorizer with the XGBoost classifier in a scikit-learn pipeline\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from sklearn.pipeline import Pipeline\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom xgboost import XGBClassifier\\n\\nle = LabelEncoder()\\ny_train_encoded = le.fit_transform(y_train)\\ny_test_encoded = le.transform(y_test)\\n\\nsteps = [(\\\"Ollama\\\", OllamaVectorizer()), (\\\"Clf\\\", XGBClassifier())]\\nclf = Pipeline(steps)\\nclf.fit(X_train, y_train_encoded)\\nyh = clf.predict(X_test)\\n\"}],[\"$\",\"hr\",null,{}],[\"$\",\"h2\",null,{\"id\":\"api-reference\",\"children\":\"API Reference\"}],[\"$\",\"p\",null,{\"children\":\"The following API reference only lists the parameters needed for the initialization of the estimator. The remaining methods follow the syntax of a scikit-learn transformer.\"}],[\"$\",\"h3\",null,{\"id\":\"ollama-vectorizer\",\"children\":\"OllamaVectorizer\"}],[\"$\",\"$L10\",null,{\"language\":\"python\",\"children\":\"from skllm.models.gpt.vectorization import OllamaVectorizer\\n\"}],[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"scope\":\"col\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Parameter\"}]}],[\"$\",\"th\",null,{\"scope\":\"col\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Type\"}]}],[\"$\",\"th\",null,{\"scope\":\"col\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Description\"}]}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"model\"}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"str\"}]}],[\"$\",\"td\",null,{\"children\":\"Model to use, by default \\\"text-embedding-3-small\\\".\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"batch_size\"}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"int\"}]}],[\"$\",\"td\",null,{\"children\":\"Number of samples per request, by default 1.\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"key\"}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"Optional[str]\"}]}],[\"$\",\"td\",null,{\"children\":\"Estimator-specific API key; if None, retrieved from the global config, by default None.\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"org\"}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"Optional[str]\"}]}],[\"$\",\"td\",null,{\"children\":\"Estimator-specific ORG key; if None, retrieved from the global config, by default None.\"}]]}]]}]]}]]}]]}],[\"$\",\"$L11\",null,{}]]}],[\"$\",\"$L12\",null,{\"tableOfContents\":[{\"level\":2,\"id\":\"overview\",\"title\":\"Overview\",\"children\":[]},{\"level\":2,\"id\":\"api-reference\",\"title\":\"API Reference\",\"children\":[{\"level\":3,\"id\":\"ollama-vectorizer\",\"title\":\"OllamaVectorizer\"}]}]}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Text vectorization - Docs\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Learn about text vectorization.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/bayreuth_ai_association/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>